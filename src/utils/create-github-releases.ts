import { existsSync, readFileSync, readdirSync } from "node:fs";
import { basename, join } from "node:path";
import { debug, endGroup, error, getState, info, startGroup, warning } from "@actions/core";
import { exec } from "@actions/exec";
import { context, getOctokit } from "@actions/github";
import { createReleaseAssetAttestation } from "./create-attestation.js";
import type { TagInfo } from "./determine-tag-strategy.js";
import { findPackagePath } from "./find-package-path.js";
import type { PackagePublishResult, TargetPublishResult } from "./generate-publish-summary.js";
import { getPackagePageUrl } from "./generate-publish-summary.js";

/**
 * Result of creating GitHub releases
 */
export interface CreateReleasesResult {
	/** Whether all releases were created successfully */
	success: boolean;
	/** Created releases */
	releases: ReleaseInfo[];
	/** Tags that were created */
	createdTags: string[];
	/** Errors encountered */
	errors: string[];
}

/**
 * Information about a created release
 */
export interface ReleaseInfo {
	/** Release tag name */
	tag: string;
	/** Release URL */
	url: string;
	/** Release ID */
	id: number;
	/** Uploaded assets */
	assets: AssetInfo[];
}

/**
 * Information about an uploaded asset
 */
export interface AssetInfo {
	/** Asset name */
	name: string;
	/** Download URL */
	downloadUrl: string;
	/** Asset size in bytes */
	size: number;
	/** Attestation URL if attestation was created */
	attestationUrl?: string;
	/** Registry this tarball was published to (if multi-target) */
	registry?: string;
}

/**
 * Extract release notes from CHANGELOG.md for a specific version
 *
 * @param changelogPath - Path to CHANGELOG.md
 * @param version - Version to extract notes for
 * @returns Release notes markdown or undefined
 */
function extractReleaseNotes(changelogPath: string, version: string): string | undefined {
	if (!existsSync(changelogPath)) {
		return undefined;
	}

	const content = readFileSync(changelogPath, "utf-8");
	const lines = content.split("\n");

	// Find the section for this version
	// Changesets format: ## 1.0.0 or ## @scope/pkg@1.0.0
	const versionPattern = new RegExp(`^##\\s+(?:@[^@]+@)?${version.replace(/[.*+?^${}()|[\]\\]/g, "\\$&")}\\s*$`);
	const nextVersionPattern = /^##\s+/;

	let inSection = false;
	const sectionLines: string[] = [];

	for (const line of lines) {
		if (versionPattern.test(line)) {
			inSection = true;
			continue;
		}

		if (inSection) {
			if (nextVersionPattern.test(line)) {
				break;
			}
			sectionLines.push(line);
		}
	}

	if (sectionLines.length === 0) {
		return undefined;
	}

	// Trim leading/trailing empty lines
	while (sectionLines.length > 0 && sectionLines[0].trim() === "") {
		sectionLines.shift();
	}
	while (sectionLines.length > 0 && sectionLines[sectionLines.length - 1].trim() === "") {
		sectionLines.pop();
	}

	return sectionLines.join("\n");
}

/**
 * Get prefix for asset name from target directory
 *
 * Uses the last segment of the directory path (e.g., "dist/npm" -> "npm")
 *
 * @param directory - Target directory path
 * @returns Directory suffix for asset name prefix
 */
function getDirectoryPrefix(directory: string): string {
	const parts = directory.split("/").filter(Boolean);
	return parts[parts.length - 1] || "dist";
}

/**
 * Get the unscoped name from a package name
 *
 * @example
 * getUnscopedName("@savvy-web/rslib-builder") // returns "rslib-builder"
 * getUnscopedName("my-package") // returns "my-package"
 *
 * @param packageName - Full package name (may include scope)
 * @returns Unscoped package name
 */
function getUnscopedName(packageName: string): string {
	if (packageName.startsWith("@") && packageName.includes("/")) {
		return packageName.split("/")[1];
	}
	return packageName;
}

/**
 * Find API documentation file in a directory
 *
 * Looks for files matching the pattern `<unscopedPackageName>.api.json`
 * which are generated by API Extractor.
 *
 * @param directory - Directory to search in (may be undefined for targets without a directory)
 * @param packageName - Package name to derive the file name from
 * @returns Path to the API file if found, undefined otherwise
 */
function findApiDocFile(directory: string | undefined, packageName: string): string | undefined {
	if (!directory) {
		return undefined;
	}

	const unscopedName = getUnscopedName(packageName);
	const apiFileName = `${unscopedName}.api.json`;
	const apiFilePath = join(directory, apiFileName);

	if (existsSync(apiFilePath)) {
		debug(`Found API doc file: ${apiFilePath}`);
		return apiFilePath;
	}

	return undefined;
}

/**
 * Get the pack command for the current package manager
 *
 * @param packageManager - Package manager to use (npm, pnpm, yarn, bun)
 * @returns Command and args for creating a package tarball
 */
function getPackCommand(packageManager: string): { cmd: string; args: string[] } {
	// Use each package manager's dlx/npx to run npm pack for consistent behavior
	// This ensures we use a compatible npm version, not whatever the user has installed
	// --json flag provides structured output for reliable parsing
	switch (packageManager) {
		case "pnpm":
			return { cmd: "pnpm", args: ["dlx", "npm", "pack", "--json"] };
		case "yarn":
			// yarn dlx is for yarn 2+, yarn 1.x uses npx
			return { cmd: "yarn", args: ["dlx", "npm", "pack", "--json"] };
		case "bun":
			return { cmd: "bun", args: ["x", "npm", "pack", "--json"] };
		default:
			// npm uses npx
			return { cmd: "npx", args: ["npm", "pack", "--json"] };
	}
}

/**
 * npm pack --json output structure
 */
interface NpmPackResult {
	filename: string;
	name: string;
	version: string;
}

/**
 * Find package artifacts to upload
 *
 * @param packagePath - Path to the package directory
 * @param packageManager - Package manager to use (npm, pnpm, yarn, bun)
 * @returns Array of artifact file paths
 */
async function findPackageArtifacts(packagePath: string, packageManager: string): Promise<string[]> {
	const artifacts: string[] = [];

	// Check for .tgz files (from npm pack)
	const files = readdirSync(packagePath);
	for (const file of files) {
		if (file.endsWith(".tgz")) {
			artifacts.push(join(packagePath, file));
		}
	}

	// If no tgz found, try to create one
	if (artifacts.length === 0) {
		try {
			const { cmd, args } = getPackCommand(packageManager);
			let output = "";
			await exec(cmd, args, {
				cwd: packagePath,
				listeners: {
					stdout: (data: Buffer) => {
						output += data.toString();
					},
				},
			});

			// Parse JSON output from npm pack --json
			const packResults = JSON.parse(output.trim()) as NpmPackResult[];
			for (const result of packResults) {
				if (result.filename) {
					artifacts.push(join(packagePath, result.filename));
					debug(`npm pack created: ${result.filename} (${result.name}@${result.version})`);
				}
			}
		} catch (err) {
			debug(`Failed to create package tarball: ${err instanceof Error ? err.message : String(err)}`);
		}
	}

	return artifacts;
}

/**
 * Configure git identity for creating annotated tags
 *
 * @remarks
 * Annotated tags require a committer identity. This function configures
 * git user.name and user.email based on the GitHub App that created the token.
 */
async function configureGitIdentity(): Promise<void> {
	const appSlug = getState("appSlug");

	// Use app identity or fall back to github-actions bot
	const userName = appSlug ? `${appSlug}[bot]` : "github-actions[bot]";
	// Use a generic noreply email format - the exact ID doesn't matter for tag creation
	const userEmail = appSlug
		? `${appSlug}[bot]@users.noreply.github.com`
		: "41898282+github-actions[bot]@users.noreply.github.com";

	debug(`Configuring git identity: ${userName} <${userEmail}>`);

	await exec("git", ["config", "user.name", userName]);
	await exec("git", ["config", "user.email", userEmail]);
}

/**
 * Create a signed git tag via the GitHub API
 *
 * @remarks
 * Tags created via the GitHub API with a GitHub App token are automatically
 * verified/signed by GitHub, similar to commits created via the API.
 *
 * @param tagName - Name of the tag to create
 * @param message - Tag message
 * @param dryRun - Whether to skip actual tag creation
 * @returns Whether the tag was created successfully
 */
async function createGitTag(tagName: string, message: string, dryRun: boolean): Promise<boolean> {
	if (dryRun) {
		info(`[DRY RUN] Would create tag: ${tagName}`);
		return true;
	}

	const token = getState("token");
	if (!token) {
		error("No token available for creating signed tag");
		return false;
	}

	const octokit = getOctokit(token);
	const { owner, repo } = context.repo;

	try {
		// Get the current HEAD commit SHA
		let stdout = "";
		await exec("git", ["rev-parse", "HEAD"], {
			listeners: {
				stdout: (data: Buffer) => {
					stdout += data.toString();
				},
			},
			silent: true,
		});
		const headSha = stdout.trim();

		// Create an annotated tag object via the API (this makes it signed/verified)
		const { data: tagObject } = await octokit.rest.git.createTag({
			owner,
			repo,
			tag: tagName,
			message,
			object: headSha,
			type: "commit",
		});

		// Create a reference pointing to the tag object
		await octokit.rest.git.createRef({
			owner,
			repo,
			ref: `refs/tags/${tagName}`,
			sha: tagObject.sha,
		});

		info(`Created and pushed tag: ${tagName}`);
		return true;
	} catch (err) {
		error(`Failed to create tag ${tagName}: ${err instanceof Error ? err.message : String(err)}`);
		return false;
	}
}

/**
 * Create GitHub releases for published packages
 *
 * @remarks
 * This function:
 * 1. Creates git tags for each release
 * 2. Creates GitHub releases with release notes from CHANGELOG
 * 3. Uploads package artifacts to each release
 *
 * @param tags - Tags to create releases for
 * @param publishResults - Results from publishing packages
 * @param packageManager - Package manager to use (npm, pnpm, yarn, bun)
 * @param dryRun - Whether to skip actual creation
 * @returns Promise resolving to release creation result
 */
export async function createGitHubReleases(
	tags: TagInfo[],
	publishResults: PackagePublishResult[],
	packageManager: string,
	dryRun: boolean,
): Promise<CreateReleasesResult> {
	const token = getState("token");
	if (!token) {
		throw new Error("No token available from state - ensure pre.ts ran successfully");
	}
	const octokit = getOctokit(token);

	const releases: ReleaseInfo[] = [];
	const createdTags: string[] = [];
	const errors: string[] = [];

	startGroup("Creating GitHub releases");

	// Configure git identity for creating annotated tags (required for non-dry-run)
	if (!dryRun) {
		await configureGitIdentity();
	}

	for (const tag of tags) {
		info(`Processing release for ${tag.name}...`);

		// Find packages associated with this tag
		const associatedPackages = publishResults.filter((pkg) => {
			if (tag.packageName.includes(", ")) {
				// Fixed versioning - multiple packages
				return tag.packageName.includes(pkg.name);
			}
			return pkg.name === tag.packageName;
		});

		if (associatedPackages.length === 0) {
			warning(`No packages found for tag ${tag.name}`);
			continue;
		}

		// Build release notes
		let releaseNotes = "";

		for (const pkg of associatedPackages) {
			// Try to find CHANGELOG in the package directory using workspace-tools
			const pkgPath = findPackagePath(pkg.name);
			const changelogPaths: string[] = [];

			if (pkgPath) {
				changelogPaths.push(join(pkgPath, "CHANGELOG.md"));
			}
			// Fall back to root changelog for single-package repos
			changelogPaths.push(join(process.cwd(), "CHANGELOG.md"));

			let notes: string | undefined;
			for (const changelogPath of changelogPaths) {
				debug(`Looking for CHANGELOG at: ${changelogPath}`);
				notes = extractReleaseNotes(changelogPath, pkg.version);
				if (notes) {
					debug(`Found release notes for ${pkg.name}@${pkg.version} in ${changelogPath}`);
					break;
				}
			}

			if (associatedPackages.length > 1) {
				releaseNotes += `## ${pkg.name}\n\n`;
			}
			releaseNotes += notes || `Released version ${pkg.version}`;
			releaseNotes += "\n\n";
		}

		// Build publish summary table
		// Collect all successful targets with their info
		const publishedTargets: Array<{
			pkg: PackagePublishResult;
			target: TargetPublishResult;
			registryName: string;
			packageUrl: string | undefined;
		}> = [];

		for (const pkg of associatedPackages) {
			for (const target of pkg.targets.filter((t) => t.success)) {
				const registryName = target.target.registry?.includes("npmjs.org")
					? "npm"
					: target.target.registry?.includes("pkg.github.com")
						? "GitHub Packages"
						: target.target.registry
							? new URL(target.target.registry).hostname
							: "jsr.io";

				const packageUrl = getPackagePageUrl(target.target.registry ?? null, pkg.name, pkg.version);

				publishedTargets.push({ pkg, target, registryName, packageUrl });
			}
		}

		if (publishedTargets.length > 0) {
			releaseNotes += "---\n\n";
			releaseNotes += "### Publish Summary\n\n";
			releaseNotes += "| Registry | Package | SBOM | API | Provenance |\n";
			releaseNotes += "|----------|---------|------|-----|------------|\n";

			for (const { pkg, target, registryName, packageUrl } of publishedTargets) {
				const packageCell = packageUrl ? `[${pkg.name}@${pkg.version}](${packageUrl})` : `${pkg.name}@${pkg.version}`;

				// SBOM cell - will be updated after assets are uploaded
				const sbomCell = target.sbomPath ? "ðŸ“¦" : "â€”";

				// API doc cell - will be updated after assets are uploaded
				const apiDocExists = findApiDocFile(target.target.directory, pkg.name) !== undefined;
				const apiCell = apiDocExists ? "ðŸ“„" : "â€”";

				// Provenance cell - combine npm provenance and GitHub attestation
				const provenanceParts: string[] = [];
				if (target.attestationUrl) {
					provenanceParts.push(`[Sigstore](${target.attestationUrl})`);
				}
				if (pkg.githubAttestationUrl) {
					provenanceParts.push(`[GitHub](${pkg.githubAttestationUrl})`);
				}
				if (target.sbomAttestationUrl) {
					provenanceParts.push(`[SBOM](${target.sbomAttestationUrl})`);
				}
				const provenanceCell = provenanceParts.length > 0 ? provenanceParts.join(", ") : "â€”";

				releaseNotes += `| ${registryName} | ${packageCell} | ${sbomCell} | ${apiCell} | ${provenanceCell} |\n`;
			}
		}

		// Create git tag
		const tagMessage = `Release ${tag.name}`;
		const tagCreated = await createGitTag(tag.name, tagMessage, dryRun);

		if (!tagCreated && !dryRun) {
			errors.push(`Failed to create tag ${tag.name}`);
			continue;
		}

		createdTags.push(tag.name);

		// Create GitHub release
		if (dryRun) {
			info(`[DRY RUN] Would create GitHub release for ${tag.name}`);
			releases.push({
				tag: tag.name,
				url: `https://github.com/${context.repo.owner}/${context.repo.repo}/releases/tag/${tag.name}`,
				id: 0,
				assets: [],
			});
			continue;
		}

		try {
			const release = await octokit.rest.repos.createRelease({
				owner: context.repo.owner,
				repo: context.repo.repo,
				tag_name: tag.name,
				name: tag.name,
				body: releaseNotes.trim(),
				draft: false,
				prerelease: tag.version.includes("-"),
			});

			info(`Created release: ${release.data.html_url}`);

			const releaseInfo: ReleaseInfo = {
				tag: tag.name,
				url: release.data.html_url,
				id: release.data.id,
				assets: [],
			};

			// Upload artifacts for each package using tarball paths from publish results
			for (const pkg of associatedPackages) {
				// Collect successful targets with tarball paths
				const targetsWithTarballs = pkg.targets.filter((t) => t.success && t.tarballPath);

				if (targetsWithTarballs.length === 0) {
					// Fallback to old behavior for packages without tarball info
					const pkgPath = findPackagePath(pkg.name);
					if (!pkgPath) {
						warning(`Could not find path for package ${pkg.name}, skipping artifact upload`);
						continue;
					}
					const artifacts = await findPackageArtifacts(pkgPath, packageManager);

					for (const artifactPath of artifacts) {
						try {
							const fileName = basename(artifactPath);
							const fileContent = readFileSync(artifactPath);

							info(`Uploading asset: ${fileName}`);

							const asset = await octokit.rest.repos.uploadReleaseAsset({
								owner: context.repo.owner,
								repo: context.repo.repo,
								release_id: release.data.id,
								name: fileName,
								data: fileContent as unknown as string,
							});

							info(`Uploaded: ${asset.data.browser_download_url}`);

							const attestationResult = await createReleaseAssetAttestation(
								artifactPath,
								pkg.name,
								pkg.version,
								dryRun,
							);

							releaseInfo.assets.push({
								name: fileName,
								downloadUrl: asset.data.browser_download_url,
								size: asset.data.size,
								attestationUrl: attestationResult.success ? attestationResult.attestationUrl : undefined,
							});

							if (attestationResult.success && attestationResult.attestationUrl) {
								info(`  âœ“ Created attestation: ${attestationResult.attestationUrl}`);
							}
						} catch (err) {
							warning(`Failed to upload artifact ${artifactPath}: ${err instanceof Error ? err.message : String(err)}`);
						}
					}
					continue;
				}

				// Check if we have multiple unique directories (multi-target with different content)
				const uniqueDirectories = new Set(targetsWithTarballs.map((t) => t.target.directory));
				const needsPrefix = uniqueDirectories.size > 1;

				// Track uploaded paths to avoid duplicates (same tarball for multiple targets)
				const uploadedPaths = new Set<string>();

				// Track SBOM URLs for release notes update
				const sbomAssetUrls = new Map<string, string>();

				// Track API doc URLs for release notes update
				const apiDocAssetUrls = new Map<string, string>();

				for (const targetResult of targetsWithTarballs) {
					const artifactPath = targetResult.tarballPath;
					if (!artifactPath) continue; // Type guard (already filtered but TS doesn't know)

					// Skip if already uploaded (same tarball used for multiple targets sharing directory)
					if (uploadedPaths.has(artifactPath)) continue;
					uploadedPaths.add(artifactPath);

					try {
						const originalFileName = basename(artifactPath);
						// Prefix with directory name if multiple directories (e.g., "npm-my-package-1.0.0.tgz")
						const fileName = needsPrefix
							? `${getDirectoryPrefix(targetResult.target.directory)}-${originalFileName}`
							: originalFileName;

						const fileContent = readFileSync(artifactPath);

						info(`Uploading asset: ${fileName}${needsPrefix ? ` (from ${targetResult.target.directory})` : ""}`);

						const asset = await octokit.rest.repos.uploadReleaseAsset({
							owner: context.repo.owner,
							repo: context.repo.repo,
							release_id: release.data.id,
							name: fileName,
							data: fileContent as unknown as string,
						});

						info(`Uploaded: ${asset.data.browser_download_url}`);

						const attestationResult = await createReleaseAssetAttestation(artifactPath, pkg.name, pkg.version, dryRun);

						releaseInfo.assets.push({
							name: fileName,
							downloadUrl: asset.data.browser_download_url,
							size: asset.data.size,
							attestationUrl: attestationResult.success ? attestationResult.attestationUrl : undefined,
							registry: targetResult.target.registry ?? undefined,
						});

						if (attestationResult.success && attestationResult.attestationUrl) {
							info(`  âœ“ Created attestation: ${attestationResult.attestationUrl}`);
						}

						// Upload SBOM if available
						if (targetResult.sbomPath && existsSync(targetResult.sbomPath)) {
							try {
								const sbomFileName = basename(targetResult.sbomPath);
								const sbomContent = readFileSync(targetResult.sbomPath);

								info(`Uploading SBOM: ${sbomFileName}`);

								const sbomAsset = await octokit.rest.repos.uploadReleaseAsset({
									owner: context.repo.owner,
									repo: context.repo.repo,
									release_id: release.data.id,
									name: sbomFileName,
									data: sbomContent as unknown as string,
								});

								info(`Uploaded SBOM: ${sbomAsset.data.browser_download_url}`);

								// Track SBOM URL for release notes
								sbomAssetUrls.set(targetResult.target.directory, sbomAsset.data.browser_download_url);

								releaseInfo.assets.push({
									name: sbomFileName,
									downloadUrl: sbomAsset.data.browser_download_url,
									size: sbomAsset.data.size,
								});
							} catch (sbomErr) {
								warning(
									`Failed to upload SBOM ${targetResult.sbomPath}: ${sbomErr instanceof Error ? sbomErr.message : String(sbomErr)}`,
								);
							}
						}

						// Upload API documentation file if available
						const apiDocPath = findApiDocFile(targetResult.target.directory, pkg.name);
						if (apiDocPath) {
							try {
								const apiDocFileName = basename(apiDocPath);
								// Prefix with directory name if multiple targets
								const finalApiDocFileName = needsPrefix
									? `${getDirectoryPrefix(targetResult.target.directory)}-${apiDocFileName}`
									: apiDocFileName;
								const apiDocContent = readFileSync(apiDocPath);

								info(`Uploading API doc: ${finalApiDocFileName}`);

								const apiDocAsset = await octokit.rest.repos.uploadReleaseAsset({
									owner: context.repo.owner,
									repo: context.repo.repo,
									release_id: release.data.id,
									name: finalApiDocFileName,
									data: apiDocContent as unknown as string,
								});

								info(`Uploaded API doc: ${apiDocAsset.data.browser_download_url}`);

								// Track API doc URL for release notes
								apiDocAssetUrls.set(targetResult.target.directory, apiDocAsset.data.browser_download_url);

								releaseInfo.assets.push({
									name: finalApiDocFileName,
									downloadUrl: apiDocAsset.data.browser_download_url,
									size: apiDocAsset.data.size,
								});
							} catch (apiDocErr) {
								warning(
									`Failed to upload API doc ${apiDocPath}: ${apiDocErr instanceof Error ? apiDocErr.message : String(apiDocErr)}`,
								);
							}
						}
					} catch (err) {
						warning(`Failed to upload artifact ${artifactPath}: ${err instanceof Error ? err.message : String(err)}`);
					}
				}

				// Update release notes with SBOM links
				if (sbomAssetUrls.size > 0) {
					// Replace the placeholder SBOM cells with actual links
					for (const [_dir, sbomUrl] of sbomAssetUrls) {
						// Update release notes to replace "ðŸ“¦" with actual link for this target
						releaseNotes = releaseNotes.replace(
							/\| ðŸ“¦ \| (ðŸ“„|â€”) \| (\[Sigstore\]|\[GitHub\]|\[SBOM\]|â€”)/,
							`| [ðŸ“¦](${sbomUrl}) | $1 | $2`,
						);
					}
				}

				// Update release notes with API doc links
				if (apiDocAssetUrls.size > 0) {
					// Replace the placeholder API doc cells with actual links
					for (const [_dir, apiDocUrl] of apiDocAssetUrls) {
						// Update release notes to replace "ðŸ“„" with actual link for this target
						releaseNotes = releaseNotes.replace(
							/\| ðŸ“„ \| (\[Sigstore\]|\[GitHub\]|\[SBOM\]|â€”)/,
							`| [ðŸ“„](${apiDocUrl}) | $1`,
						);
					}
				}
			}

			// Update the release body with SBOM links
			if (releaseInfo.assets.length > 0) {
				try {
					await octokit.rest.repos.updateRelease({
						owner: context.repo.owner,
						repo: context.repo.repo,
						release_id: release.data.id,
						body: releaseNotes.trim(),
					});
					info(`Updated release notes with asset links`);
				} catch (err) {
					warning(`Failed to update release notes: ${err instanceof Error ? err.message : String(err)}`);
				}
			}

			releases.push(releaseInfo);
		} catch (err) {
			const errorMessage = `Failed to create release for ${tag.name}: ${err instanceof Error ? err.message : String(err)}`;
			error(errorMessage);
			errors.push(errorMessage);
		}
	}

	endGroup();

	return {
		success: errors.length === 0,
		releases,
		createdTags,
		errors,
	};
}
